{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EiyUOsN7zBt8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W61Kbzy8caY",
        "outputId": "45f75dc9-0b10-45ce-f548-9d000f23b910"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/103_classes_filtered.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df['title']\n",
        "y = df['categories']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381803,)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"['cs.NE', 'cs.AI']\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e9GTcYmzBt_",
        "outputId": "4489d766-8e8c-4efd-b75a-89f1948b9ab0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['astro-ph.IM', 'cond-mat.dis-nn', 'cond-mat.mtrl-sci',\n",
              "       'cond-mat.stat-mech', 'cs.AI', 'cs.AR', 'cs.CC', 'cs.CE', 'cs.CG',\n",
              "       'cs.CL', 'cs.CR', 'cs.CV', 'cs.CY', 'cs.DB', 'cs.DC', 'cs.DL',\n",
              "       'cs.DM', 'cs.DS', 'cs.ET', 'cs.FL', 'cs.GL', 'cs.GR', 'cs.GT',\n",
              "       'cs.HC', 'cs.IR', 'cs.IT', 'cs.LG', 'cs.LO', 'cs.MA', 'cs.MM',\n",
              "       'cs.MS', 'cs.NA', 'cs.NE', 'cs.NI', 'cs.OH', 'cs.OS', 'cs.PF',\n",
              "       'cs.PL', 'cs.RO', 'cs.SC', 'cs.SD', 'cs.SE', 'cs.SI', 'cs.SY',\n",
              "       'econ.EM', 'econ.GN', 'econ.TH', 'eess.AS', 'eess.IV', 'eess.SP',\n",
              "       'eess.SY', 'hep-ex', 'math-ph', 'math.AC', 'math.AG', 'math.AP',\n",
              "       'math.AT', 'math.CA', 'math.CO', 'math.CT', 'math.DG', 'math.DS',\n",
              "       'math.FA', 'math.GR', 'math.IT', 'math.LO', 'math.MG', 'math.MP',\n",
              "       'math.NA', 'math.NT', 'math.OC', 'math.PR', 'math.RA', 'math.RT',\n",
              "       'math.ST', 'nlin.AO', 'nlin.CD', 'nlin.CG', 'physics.ao-ph',\n",
              "       'physics.app-ph', 'physics.bio-ph', 'physics.chem-ph',\n",
              "       'physics.comp-ph', 'physics.data-an', 'physics.flu-dyn',\n",
              "       'physics.geo-ph', 'physics.med-ph', 'physics.optics',\n",
              "       'physics.soc-ph', 'q-bio.BM', 'q-bio.GN', 'q-bio.MN', 'q-bio.NC',\n",
              "       'q-bio.PE', 'q-bio.QM', 'q-fin.EC', 'q-fin.ST', 'quant-ph',\n",
              "       'stat.AP', 'stat.CO', 'stat.ME', 'stat.ML', 'stat.TH'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from ast import literal_eval\n",
        "y = [literal_eval(i) for i in y]\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_binarized = mlb.fit_transform(y)\n",
        "mlb.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('./data/y_binarized_data.pkl','wb') as f:\n",
        "    pickle.dump(y_binarized,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIzzKETX_FqM",
        "outputId": "93abf77d-64fb-4604-d389-410b36964e0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_binarized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVbuJxGzWwky",
        "outputId": "70088de2-8bf7-48f0-c407-5fa063c7d0b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381803,)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3VYMojVYO-U"
      },
      "source": [
        "title preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a_8a6QIW2Reu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/siddhipotdar/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W7PXyjsa2uU",
        "outputId": "8945fee2-649f-4493-848f-e9e300b9159f"
      },
      "outputs": [],
      "source": [
        "# tokenize words and remove stopwords\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "tokenizer = nltk.WordPunctTokenizer()\n",
        "\n",
        "def preprocess(text: str) -> str:\n",
        "    text = tokenizer.tokenize(text.lower().strip())\n",
        "    text = [ x for x in text if x not in stopwords]\n",
        "    return ' '.join(text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_token = []\n",
        "for item in X:\n",
        "    item = re.sub(r'[^a-zA-Z\\s]','', item, re.I)\n",
        "    X_token.append(preprocess(item))\n",
        "    #print(item)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXtbdBB7nTZr",
        "outputId": "cd97ad22-b6b0-4cb5-88df-4983bc80249f"
      },
      "outputs": [],
      "source": [
        "X_token = np.array(X_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
        "# !unzip v0.9.2.zip\n",
        "# !cd fastText-0.9.2\n",
        "# !pip install ./fastText-0.9.2/.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finding fastttext sentence embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "#fasttext.util.download_model('en', if_exists='ignore')\n",
        "model = fasttext.load_model('./fastText-0.9.2/cc.en.300.bin')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make a dictionary, store repeating words from the dataset inside it\n",
        "\n",
        "embedding_map = dict()\n",
        "for sentence in X_token:\n",
        "    for word in sentence.split():\n",
        "        if word not in embedding_map:\n",
        "            embedding_map[word] = model.get_word_vector(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(embedding_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_fasttext_embeddings(x_data, y_data):\n",
        "    sentence_embedding = []\n",
        "    sample = 0\n",
        "    for sentence in x_data:\n",
        "        word_embedding = np.zeros((300,))\n",
        "        count = 0\n",
        "        for word in sentence.split():\n",
        "            word_embedding+=embedding_map[word]\n",
        "            count += 1\n",
        "        if count != 0:\n",
        "            sentence_embedding.append(word_embedding/count)\n",
        "        else:\n",
        "            y_data = np.delete(y_data, sample, axis=0)\n",
        "            #print(sentence_embedding)\n",
        "        sample+=1\n",
        "    return sentence_embedding, y_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_embeddings, y_label = get_fasttext_embeddings(X_token, y_binarized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "381800"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_embeddings)\n",
        "#len(train_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "381800"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./data/X_fasttext_embeddings', X_embeddings)\n",
        "np.save('./data/y_embeddings', y_label)\n",
        "np.save('./data/y_tags',mlb.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # oversample\n",
        "# max_count = sorted_class_distribution_w_threshold['count'][0]\n",
        "# print(max_count)\n",
        "# over_sample_cnt = int(max_count*0.3)\n",
        "# print(int(over_sample_cnt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Imbalanced-learn currently supports binary, multiclass and binarized encoded multiclasss targets. Multilabel and multioutput targets are not supported.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/siddhipotdar/Documents/CS-6375-Arxiv/Arxiv-pred/Arxiv_data_50pct_preprocessing_features.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddhipotdar/Documents/CS-6375-Arxiv/Arxiv-pred/Arxiv_data_50pct_preprocessing_features.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddhipotdar/Documents/CS-6375-Arxiv/Arxiv-pred/Arxiv_data_50pct_preprocessing_features.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ros \u001b[39m=\u001b[39m RandomOverSampler(random_state\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/siddhipotdar/Documents/CS-6375-Arxiv/Arxiv-pred/Arxiv_data_50pct_preprocessing_features.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_resampled, Y_resampled \u001b[39m=\u001b[39m ros\u001b[39m.\u001b[39;49mfit_resample(X_embeddings, y_label)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/base.py:82\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m check_classification_targets(y)\n\u001b[1;32m     81\u001b[0m arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m---> 82\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     88\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resample(X, y)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/over_sampling/_random_over_sampler.py:156\u001b[0m, in \u001b[0;36mRandomOverSampler._check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X_y\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m--> 156\u001b[0m     y, binarize_y \u001b[39m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    157\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    158\u001b[0m         X,\n\u001b[1;32m    159\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         force_all_finite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m X, y, binarize_y\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/utils/_validation.py:147\u001b[0m, in \u001b[0;36mcheck_target_type\u001b[0;34m(y, indicate_one_vs_all)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m type_y \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(y\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 147\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mImbalanced-learn currently supports binary, multiclass and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbinarized encoded multiclasss targets. Multilabel and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmultioutput targets are not supported.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mValueError\u001b[0m: Imbalanced-learn currently supports binary, multiclass and binarized encoded multiclasss targets. Multilabel and multioutput targets are not supported."
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "dfad143759263861f218098ffac96349330b525a4ec8957cf3d4a95ef932a418"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
